
### 7.1 Optional: Setup data replication by using replication storage rules and subrules

Two or optionally three IBM Storage Protect servers that are configured by using the blueprint configuration script can be updated to run replication storage rules. You must specify the parameter **ACTIVE=Yes** to enable the processing of the replication storage rule at the scheduled time.

**Before you begin**

1. If you are not familiar with the concepts of data replication, review the following information: </br>**Data replication** </br> You can use replication storage rules to create additional copies of data on another server. To learn the basic concepts of data replication, see [Replicating client data to multiple servers](https://www.ibm.com/docs/en/storage-protect/8.1.22?topic=servers-replicating-data-multiple) in IBM Documentation.
1. Consider whether replication will run in one direction from a source replication server to target replication servers, or if each server will replicate to the other server (acting as both a source and a target replication server). The Blueprint configuration script creates an inactive replication storage rule with ACTIONTYPE=NOREPLICATING parameter value on all servers. Activate the replication storage rule only on source replication servers. You need to create a replication subrule for the parent replication storage rule to enable the replication storage rule.
1. To optimize data replication operations, ensure that the source replication server and target replication servers have the same hardware configuration, for example:
   * Allocate the same amount of storage capacity on both servers for the database, logs, and storage pools.
   * Use the same type of disks for the database and active log. For example, use solid-state disks for both the database and active log on both servers.
   * Ensure that both servers have the same number of processor cores and a similar amount of read-only memory (RAM). If both servers are used for client backup operations, allocate the same number of processor cores to both servers. However, if the target server is used only for replication, but not for client backup operations, you can allocate half as many processor cores (but no fewer than six) to the target server.

**About this task**

You can setup data replication by using the **Add Server Pair** wizard in the Operations Center or by following the `Procedure`.

**Procedure**

The following manual example assumes that two servers, TAPSRV01 and TAPSRV02, were configured by using the blueprint specifications. The placeholders noted for passwords must match the value that was provided for the server password during the initial configuration. This procedure sets up the data replication so that client nodes' data is backed up to TAPSRV01 and this data is replicated to TAPSRV02.

These steps configure a single storage pool that is used for holding both backup data and replicated data. You can also configure separate storage pools for backup data and replicated data.
1. Setup server-to-server communication.</br>On TAPSRV01, issue the following command:
   ```
    define server tapsrv02 serverpassword=<secretpassword> hla=tapsrv02.yourdomain.com lla=1500
   ```
   On TAPSRV02, issue the following command:
   ```
    define server tapsrv01 serverpassword=<secretpassword> hla=tapsrv01.yourdomain.com lla=1500
   ```
1. Test the communication path. </br>On TAPSRV01, issue the following command:
   ```
    ping server tapsrv02
   ```
   On TAPSRV02, issue the following command:
   ```
    ping server tapsrv01
   ```
   If the test is successful, you see results similar to the following example:
   ```
    ANR1706I Ping for server 'TAPSRV02' was able to establish a connection.
   ```
1. Export policy definitions from TAPSRV01 to TAPSRV02. Issue the following command on TAPSRV01:
   ```
    export policy * toserver=tapsrv02
   ```
1. Define TAPSRV02 as the replication target of TAPSRV01. Issue the following command on TAPSRV01:
   ```
    set replserver tapsrv02
   ```
1. Enable replication for certain nodes or all nodes. To enable replication for all nodes, issue the following command on TAPSRV01:
   ```
    update node * replstate=enabled
   ```
1. Define a storage rule to replicate data to the target replication server, TAPSRV02. To define the replication storage rule, REPLRULE1, issue the following command on TAPSRV01:
   ```
    define stgrule replrule1 tapsrv02 actiontype=replicate
   ```
1. Define an exception to the storage rule, REPLRULE1 to prevent replication of NODE1 by defining a replication subrule. To define the replication subrule, REPLSUBRULE1, issue the following command on TAPSRV01:
   ```
    define subrule replrule1 replsubrule1 node1 actiontype=noreplicating
   ```
   **Note**: You can replicate data from a source replication server to multiple target replication servers. You must define multiple replication storage rules to configure different target replication servers. Follow the instruction in step 6 to define a replication storage rule for the respective target replication server. If required, follow the instruction in step 7 to define subrules to add exceptions for the respective replication storage rules.

1. On each source replication server, activate the administrative schedule that the Blueprint configuration script created to run replication every day. Issue the following command:
   ```
    update schedule REPLICATE type=admin active=yes
   ```
    **Restriction**: Ensure that you complete this step only on source replication servers. However, if you are replicating nodes in both directions, and each server is a source and a target replication server, activate the schedule on both servers.

**What to do next**

To recover data after a disaster, follow the instructions in [Repairing and recovering data in directory-container storage pools](https://www.ibm.com/docs/en/storage-protect/8.1.22?topic=servers-repairing-recovering-data).
